import os
import json
import pandas as pd
from Bio import Entrez, Medline
from Crawling.entrez_config import Entrez

# âœ… ì—¬ê¸°ì— ê³ ì • ì¿¼ë¦¬ë¥¼ ì„¤ì • (Noneì´ë©´ ì‚¬ìš©ì ì…ë ¥ë°›ìŒ)
FIXED_QUERY: str | None = None
# FIXED_QUERY = "diabetes AND 2022[dp]"  # ì˜ˆì‹œ

def get_search_query_and_count(email: str, api_key: str) -> tuple[str, int]:
    """
    PubMed ê²€ìƒ‰ì–´ë¥¼ ë°›ì•„ ê²°ê³¼ ê°œìˆ˜ë¥¼ ë°˜í™˜í•œë‹¤.
    FIXED_QUERYê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ì„ ìš”ì²­í•œë‹¤.

    Args:
        email (str): Entrez APIì— ì‚¬ìš©í•  ì´ë©”ì¼
        api_key (str): NCBI API í‚¤

    Returns:
        tuple: (ê²€ìƒ‰ì–´, ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜)
    """
    Entrez.email = email
    Entrez.api_key = api_key

    # ğŸ” query ì„¤ì • ë°©ì‹ ê²°ì •
    if FIXED_QUERY is not None:
        query = FIXED_QUERY
        print(f"ğŸ“Œ ê³ ì • ì¿¼ë¦¬ ì‚¬ìš©: {query}")
    else:
        query = input("ğŸ” PubMedì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not query:
            print("â— ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
            exit()

    # ğŸ” ê²€ìƒ‰ ìš”ì²­
    handle = Entrez.esearch(db="pubmed", term=query, retmax=0)
    result = Entrez.read(handle)
    handle.close()

    total_count = int(result["Count"])
    return query, total_count

def run_eutilities(query: str | None = None):
    query, total_count = get_search_query_and_count(Entrez.email, Entrez.api_key)
    print(f"\nğŸ“„ ì´ {total_count:,}ê°œì˜ ê²°ê³¼ê°€ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")

    confirm = input("ğŸ“¥ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if confirm != "y":
        print("âŒ ë‹¤ìš´ë¡œë“œë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return

    max_by_site = 10000
    max_count = min(max_by_site, total_count)
    retmax = input(f"ëª‡ ê°œì˜ ë…¼ë¬¸ì„ ê°€ì ¸ì˜¬ê¹Œìš”? (ìµœëŒ€ {max_count}ê°œ): ").strip()
    retmax = int(retmax) if retmax.isdigit() else 10
    retmax = min(retmax, max_count)

    search_handle = Entrez.esearch(db="pubmed", term=query, retmax=retmax)
    search_results = Entrez.read(search_handle)
    search_handle.close()
    id_list = search_results["IdList"]

    fetch_handle = Entrez.efetch(db="pubmed", id=",".join(id_list), rettype="medline", retmode="text")
    records = list(Medline.parse(fetch_handle))
    fetch_handle.close()

    data = [{
        "pmid": r.get("PMID", ""),
        "title": r.get("TI", ""),
        "abstract": r.get("AB", ""),
        "pub_date": r.get("DP", ""),
        "journal": r.get("JT", ""),
        "authors": ", ".join(r.get("AU", []))
    } for r in records]

    save_dir = os.path.join("Database", "eutilities")
    os.makedirs(save_dir, exist_ok=True)

    filename_base = query.replace(" ", "_")[:30]
    json_path = os.path.join(save_dir, f"{filename_base}.json")
    csv_path = os.path.join(save_dir, f"{filename_base}.csv")

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    pd.DataFrame(data).to_csv(csv_path, index=False, encoding="utf-8-sig")

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ!\nğŸ“ JSON: {json_path}\nğŸ“ CSV: {csv_path}")